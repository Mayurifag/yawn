<Climb>
  <header>
    <id>yawn-enhancements-v2</id>
    <type>feature</type>
    <description>Implement several enhancements to the Yawn application, including Gemini API stream initiation timeout, streaming output, verbose mode removal, fallback model support with updated default models, prompt improvements, and a Makefile utility for user configuration.</description>
  </header>
  <newDependencies></newDependencies>
  <prerequisitChanges>Understanding of Go contexts, TOML manipulation, and Gemini SDK streaming capabilities is required. Familiarity with Makefile syntax.</prerequisitChanges>
  <relevantFiles>
    - `internal/config/config.go`
    - `internal/config/config_test.go`
    - `internal/gemini/client.go`
    - `internal/gemini/client_test.go`
    - `internal/app/app.go`
    - `internal/app/app_test.go`
    - `cmd/yawn/main.go`
    - `internal/git/git.go`
    - `README.md`
    - `Makefile`
    - `scripts/configure_settings/main.go` (new)
  </relevantFiles>
  <everythingElse>
    ## Feature Overview

    This climb focuses on improving the usability, robustness, and user experience of the Yawn AI Git Commiter. Key changes include refining API interaction timeouts to focus on stream initiation, providing real-time feedback during commit message generation, simplifying the codebase by removing verbose mode, enhancing reliability with a fallback AI model (using updated default model names), and improving the quality of generated commit messages through prompt engineering. A utility for easier user configuration via Makefile is also introduced.

    ## Requirements

    ### Functional Requirements:
    1.  **Gemini API Stream Initiation Timeout:** The application must time out if the Gemini API does not begin streaming a response within 15 seconds. If streaming begins, the connection should persist to receive the full message.
    2.  **Token-by-Token Output:** Commit messages generated by the AI must be displayed to the user token by token (streamed) in the console. The initial UI spinner should stop once streaming begins.
    3.  **Verbose Mode Removal:** All functionality and configuration related to verbose mode (`-v`, `verbose` config) must be removed.
    4.  **Fallback AI Model:**
        *   The application must support configuring a primary and a fallback Gemini model.
        *   Default primary model: `"gemini-1.5-flash-preview-0827"` (or actual latest Gemini 1.5 Flash preview).
        *   Default fallback model: `"gemini-1.5-flash-latest"` (or actual stable/latest Gemini 1.5 Flash).
        *   If the primary model fails due to stream initiation timeout, specific HTTP 5xx errors, or persistent rate limits, and a fallback model is configured, the application must attempt to generate the commit message using the fallback model.
        *   The user must be informed if the fallback model is used.
    5.  **Prompt Enhancement:** The default system prompt for the Gemini model must be updated to better guide it in identifying and summarizing the most significant changes from the provided diff.
    6.  **Makefile User Settings Command:** A `make` command (e.g., `configure-user-settings`) must be available to allow users to easily set preferred configurations (e.g., `auto_push = true`) in their global user config file (`~/.config/yawn/config.toml`).

    ### Technical Requirements:
    1.  Utilize `genai.GenerateContentStream` for streaming functionality.
    2.  Manage context timeouts appropriately for stream initiation.
    3.  Safely parse and modify TOML configuration files for the Makefile helper script.
    4.  Update all relevant tests to cover new functionalities and removals.
    5.  Verify and use correct, up-to-date Gemini model identifiers from the SDK/documentation.

    ### User Requirements:
    1.  Faster feedback during commit message generation due to streaming.
    2.  Increased reliability of commit generation due to the fallback mechanism.
    3.  Simplified configuration due to removal of verbose mode.
    4.  Potentially more accurate commit messages due to prompt enhancements.
    5.  Easier way to set common user preferences.

    ## Development Details

    ### Relevant Files:
    (Listed in header)

    ### Implementation Considerations:
    *   **Model Names:** The AI assistant implementing this must verify the exact latest available model identifiers for "gemini-1.5-flash-preview-0827" and "gemini-1.5-flash-latest" from the Google AI SDK documentation at the time of implementation.
    *   **Stream Initiation Timeout:** Careful context management is needed. The 15-second timeout applies to receiving the *first part* of the stream.
    *   **Fallback Logic:** Clearly define error conditions that trigger fallback. Ensure graceful switching and user notification.
    *   **Verbose Removal:** Requires careful removal across multiple files and extensive test updates.
    *   **Makefile Helper Script:** The Go script for `configure-user-settings` should handle TOML files carefully to preserve existing data.

    ## Testing Approach

    ### Test Cases:
    *   **Timeout:**
        *   Verify that a Gemini call times out if no stream data is received within 15 seconds.
        *   Verify that if streaming starts within 15 seconds, the full message can be received even if it takes longer than 15s.
    *   **Streaming:**
        *   Verify token-by-token output in the console.
        *   Verify UI spinner stops correctly when streaming begins.
    *   **Fallback Model:**
        *   Test scenario where primary model fails (mocked stream initiation timeout) and fallback successfully generates a message.
        *   Test scenario where primary model fails with a 5xx error (mocked) and fallback is used.
        *   Verify user notification when fallback is used.
    *   **Verbose Removal:**
        *   Confirm no verbose flag is available and no `verbose` option in generated config.
        *   Ensure `config_test.go` passes.
    *   **Makefile Command:**
        *   Verify `make configure-user-settings` correctly modifies/creates user config.
  </everythingElse>
</Climb>